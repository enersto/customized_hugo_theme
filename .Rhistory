train_woe = woebin_ply(
loan_mTrain, bins_adj)
test_woe = woebin_ply(
loan_mTest, bins_adj)
Desc(train_woe$y)
train_woe <- train_woe[,y := ifelse(y ==1,"bad","good")][,y := factor(y,levels = c("good","bad"))]
test_woe <- test_woe[,y := ifelse(y ==1,"bad","good")][,y := factor(y,levels = c("good","bad"))]
Desc(train_woe$y)
m_rf <- randomForest(y ~.,train_woe,ntree = 100)
result <- resamples(list(glm = m_glm,rf = m_rf))
summary(m_rf)
train_woe = woebin_ply(
loan_mTrain, bins_adj)
test_woe = woebin_ply(
loan_mTest, bins_adj)
train_woe <- train_woe[,y := ifelse(y ==1,"bad","good")][,y := factor(y,levels = c("good","bad"))]
test_woe <- test_woe[,y := ifelse(y ==1,"bad","good")][,y := factor(y,levels = c("good","bad"))]
library(pROC)
modelControl <- trainControl(method = "repeatedcv", number = 5, repeats = 2,
classProbs = TRUE, summaryFunction = twoClassSummary,
seeds = nn.seeds)
# glm
set.seed(6517)
m_glm <- train(y ~ ., data=train_woe,method="glm",family=binomial(link='logit'),
trControl=modelControl, metric = "ROC")
summary(m_glm)
# rf
rfGrid <- expand.grid(mtry = seq(from = 3, to = 18, by = 3))
set.seed(6517)
m_rf <- train(train_woe[, -1], train_woe$y,
method="rf",
ntree=100,
na.action=na.omit,
tuneGrid = rfGrid,
trControl= modelControl)
summary(m_rf)
train_pred = predict(m_rf, train_woe)
train_pred
test_woe = predict(m_rf, test_woe)
roc(test_woe[,y], test_pred)
auc <- roc(test_woe[,c("y")], test_pred)
test_woe[,c("y")]
train_woe = woebin_ply(
loan_mTrain, bins_adj)
test_woe = woebin_ply(
loan_mTest, bins_adj)
result <- resamples(list(glm = m_glm,rf = m_rf,gbm = m_gbm))
bwplot(result, metric="Sen")
bwplot(result, metric="Sens")
train_pred = predict(m_glm, train_woe)
test_pred = predict(m_glm, test_woe)
train_pred
test_pred
unique(test_pred)
train_pred = predict(m_glm, train_woe)
test_pred = predict(m_glm, test_woe)
unique(train_pred)
train_pred = predict(m_rf, train_woe)
test_pred = predict(m_rf, test_woe)
unique(train_pred)
Desc(train_pred)
Desc(test_pred)
m_glm <- glm(y ~.,train_woe,family = "binomial")
m_rf <- randomForest(y ~.,train_woe,ntree = 100)
train_pred = predict(m_glm, train_woe)
test_pred = predict(m_glm, test_woe)
Desc(train_pred)
train_pred = predict(m_rf, train_woe)
test_pred = predict(m_rf, test_woe)
Desc(test_pred)
test_pred
View(test_woe)
train_woe = woebin_ply(
loan_mTrain, bins_adj)
test_woe = woebin_ply(
loan_mTest, bins_adj)
train_woe <- train_woe[,y := ifelse(y ==1,"bad","good")][,y := factor(y,levels = c("good","bad"))]
test_woe <- test_woe[,y := ifelse(y ==1,"bad","good")][,y := factor(y,levels = c("good","bad"))]
m_glm <- glm(y ~.,train_woe,family = "binomial")
m_rf <- randomForest(y ~.,train_woe,ntree = 100)
train_pred = predict(m_rf, train_woe)
test_pred = predict(m_rf, test_woe)
Desc(test_pred)
summary(m_glm)
scorecard()
library(data.table)
library(scorecard)
library(caret)
library(DescTools)
options(scipen = 8)
loan = fread("C:/Users/pauke/Downloads/loan.csv")
loan <- loan[,y :=
ifelse(loan_status %in% c("Charged Off", "Default",
"Does not meet the credit policy. Status:Charged Off",
"In Grace Period","Late (16-30 days)",
"Late (31-120 days)"),"bad","good")]
loan <- loan[,y := factor(y,levels = c("good","bad"))]
knitr::kable(Desc(loan$y)[[1]][["freq"]])
loan_selected <- loan[,c("loan_amnt","int_rate","dti",
"purpose","term","annual_inc","home_ownership","emp_length","revol_bal","y")]
loan_m <- var_filter(loan_selected,y = "y")
names(loan_m)
trainIndex <- createDataPartition(loan_m$y, p = .1,
list = FALSE,
times = 1)
loan_mp <- loan_m[trainIndex,]
break_adj = list(
loan_amnt=c(8500,14000,20500))
bins_adj = woebin(
loan_mp, y="y",
breaks_list=break_adj,
print_step=0)
woebin_plot(bins_adj$loan_amnt)
set.seed(6715)
trainIndex <- createDataPartition(loan_mp$y, p = .85,
list = FALSE,
times = 1)
loan_mTrain <- loan_mp[ trainIndex,]
loan_mTest  <- loan_mp[-trainIndex,]
knitr::kable(Desc(loan_mTrain$y)[[1]][["freq"]])
train_woe = woebin_ply(
loan_mTrain, bins_adj)
test_woe = woebin_ply(
loan_mTest, bins_adj)
m1 = glm( y ~ ., family = "binomial", data = train_woe)
# summary(m1)
# Select a formula-based model by AIC
m_step = step(m1, direction="both", trace = FALSE)
m2 = eval(m_step$call)
summary(m2)$coefficients
summary(m1)$coefficients
summary(m2)$coefficients
summary(m2)
scorecard()
tidy(m2)
train_woe = woebin_ply(
loan_mTrain, bins_adj)
test_woe = woebin_ply(
loan_mTest, bins_adj)
m_glm = glm( y ~ ., family = "binomial", data = train_woe)
predictions <- predict(m_glm, newdata = test_set, type = "response")
predictions <- predict(m_glm, test_woe, type = "response")
# Look at the predictions range
range(predictions)
loan <- loan[,y :=
ifelse(loan_status %in% c("Charged Off", "Default",
"Does not meet the credit policy. Status:Charged Off",
"In Grace Period","Late (16-30 days)",
"Late (31-120 days)"),"bad","good")]
loan <- loan[,y := factor(y,levels = c("good","bad"))]
knitr::kable(Desc(loan$y)[[1]][["freq"]])
loan_selected <- loan[,c("loan_amnt","int_rate","dti",
"purpose","term","annual_inc","home_ownership","emp_length","revol_bal","y")]
loan_m <- var_filter(loan_selected,y = "y")
names(loan_m)
Desc(loan_m$y)
options(scipen = 8)
loan = fread("C:/Users/pauke/Downloads/loan.csv")
loan <- loan[,y :=
ifelse(loan_status %in% c("Charged Off", "Default",
"Does not meet the credit policy. Status:Charged Off",
"In Grace Period","Late (16-30 days)",
"Late (31-120 days)"),"bad","good")]
loan <- loan[,y := factor(y,levels = c("bad","good"))]
knitr::kable(Desc(loan$y)[[1]][["freq"]])
loan_selected <- loan[,c("loan_amnt","int_rate","dti",
"purpose","term","annual_inc","home_ownership","emp_length","revol_bal","y")]
loan_m <- var_filter(loan_selected,y = "y")
names(loan_m)
trainIndex <- createDataPartition(loan_m$y, p = .1,
list = FALSE,
times = 1)
loan_mp <- loan_m[trainIndex,]
Desc(loan_m$y)
loan_selected <- loan[,c("loan_amnt","int_rate","dti",
"purpose","term","annual_inc","home_ownership","emp_length","revol_bal","y")]
loan_m <- var_filter(loan_selected,y = "y")
names(loan_m)
trainIndex <- createDataPartition(loan_m$y, p = .1,
list = FALSE,
times = 1)
loan_mp <- loan_m[trainIndex,]
Desc(loan_m$y)
train_woe = woebin_ply(
loan_mTrain, bins_adj)
test_woe = woebin_ply(
loan_mTest, bins_adj)
m_glm = glm( y ~ ., family = "binomial", data = train_woe)
predictions <- predict(m_glm, test_woe, type = "response")
pred_cutoff_15 <- ifelse(predictions >0.15, 1,0)
table(test_woe$y,pred_cutoff_15)
log_model_logit <- glm(loan_status ~ age + emp_cat + ir_cat + loan_amnt,
family = binomial(link = logit), data = train_woe)
log_model_logit <- glm(y ~.,
family = binomial(link = logit), data = train_woe)
log_model_probit <- glm(y ~.,
family = binomial(link = probit), data = train_woe)
log_model_cloglog <-  glm(y ~.,
family = binomial(link = cloglog), data = train_woe)
# Make predictions for all models using the test set
predictions_logit <- predict(log_model_logit, newdata = test_woe, type = "response")
predictions_probit <- predict(log_model_probit, newdata = test_woe, type = "response")
predictions_cloglog <- predict(log_model_cloglog, newdata = test_woe, type = "response")
cutoff <- 0.14
class_pred_logit <- ifelse(predictions_logit > cutoff, 1, 0)
class_pred_probit <- ifelse(predictions_probit > cutoff, 1, 0)
class_pred_cloglog <- ifelse(predictions_cloglog > cutoff, 1, 0)
# Make a confusion matrix for the three models
tab_class_logit <- table(true_val,class_pred_logit)
tab_class_logit <- table(test_woe$y,class_pred_logit)
tab_class_probit <- table(test_woe$y,class_pred_probit)
tab_class_cloglog <-  table(test_woe$y,class_pred_cloglog)
acc_logit <- sum(diag(tab_class_logit)) / nrow(test_woe)
acc_probit <- sum(diag(tab_class_probit)) / nrow(test_woe)
acc_cloglog <- sum(diag(tab_class_cloglog)) / nrow(test_woe)
acc_logit
acc_probit
acc_cloglog
diag(tab_class_logit)
nrow(test_woe)
diag(tab_class_logit)
tree_undersample <- rpart(y ~ ., method = "class",
data =  train_woe)
library(rpart)
tree_undersample <- rpart(y ~ ., method = "class",
data =  train_woe)
summary(tree_undersample)
tree_prior <- rpart(y ~ ., method = "class",
data = train_woe, parms = list(prior = c(0.92, 0.07)),
control = rpart.control(cp = 0.001))
tree_prior <- rpart(y ~ ., method = "class",
data = train_woe, parms = list(prior = c(0.93, 0.07)),
control = rpart.control(cp = 0.001))
plot(tree_prior, uniform = TRUE)
plot(tree_undersample, uniform = TRUE)
names(train_woe)
tree_undersample
set.seed(345)
tree_weights <- rpart(y ~ ., method = "class",
data = train_woe, weights = case_weights,
control = rpart.control(minsplit = 5, minbucket = 2, cp = 0.001))
scorecard
set.seed(42)
model_rf_under <- caret::train(y ~ .,
data = train_woe,
method = "rf",
trControl = modelControl)
modelControl <- trainControl(method = "repeatedcv",
number = 5,
repeats = 2,
verboseIter = FALSE,
sampling = "down")
set.seed(42)
model_rf_under <- caret::train(y ~ .,
data = train_woe,
method = "rf",
trControl = modelControl)
train_woe <- train_woe[,y := ifelse(y ==1,"bad","good")][,y := factor(y,levels = c("good","bad"))]
test_woe <- test_woe[,y := ifelse(y ==1,"bad","good")][,y := factor(y,levels = c("good","bad"))]
model_rf_under <- caret::train(y ~ .,
data = train_woe,
method = "rf",
trControl = modelControl)
final_under <- data.frame(actual = test_woe$y,
predict(model_rf_under, newdata = test_woe, type = "prob"))
final_under$predict <- ifelse(final_under$bad > 0.5, "benign", "malignant")
cm_under <- confusionMatrix(final_under$predict, test_woe$y)
View(final_under)
final_under <- data.frame(actual = test_woe$y,
predict(model_rf_under, newdata = test_woe, type = "prob"))
final_under$predict <- ifelse(final_under$bad > 0.5, "bad", "good")
cm_under <- confusionMatrix(final_under$predict, test_woe$y)
View(final_under)
class(final_under$predict)
final_under <- final_under[,predict := factor(predict,levels = c("bad","good"))]
final_under <- setDT(final_under)[,predict := factor(predict,levels = c("bad","good"))]
cm_under <- confusionMatrix(final_under$predict, test_woe$y)
cm_under
install.packages("ROSE")
trainIndex <- createDataPartition(loan_m$y, p = .08,
list = FALSE,
times = 1)
loan_mp <- loan_m[trainIndex,]
Desc(loan_m$y)
break_adj = list(
loan_amnt=c(8500,14000,20500))
bins_adj = woebin(
loan_mp, y="y",
breaks_list=break_adj,
print_step=0)
woebin_plot(bins_adj$loan_amnt)
set.seed(6715)
trainIndex <- createDataPartition(loan_mp$y, p = .85,
list = FALSE,
times = 1)
loan_mTrain <- loan_mp[ trainIndex,]
loan_mTest  <- loan_mp[-trainIndex,]
knitr::kable(Desc(loan_mTrain$y)[[1]][["freq"]])
train_woe = woebin_ply(
loan_mTrain, bins_adj)
test_woe = woebin_ply(
loan_mTest, bins_adj)
modelControl <- trainControl(method = "repeatedcv",
number = 5,
repeats = 2,
verboseIter = FALSE,
sampling = "rose")
set.seed(42)
model_rf_under <- caret::train(y ~ .,
data = train_woe,
method = "rf",
trControl = modelControl)
train_woe <- train_woe[,y := ifelse(y ==1,"bad","good")][,y := factor(y,levels = c("good","bad"))]
test_woe <- test_woe[,y := ifelse(y ==1,"bad","good")][,y := factor(y,levels = c("good","bad"))]
modelControl <- trainControl(method = "repeatedcv",
number = 5,
repeats = 2,
verboseIter = FALSE,
sampling = "rose")
set.seed(42)
model_rf_under <- caret::train(y ~ .,
data = train_woe,
method = "rf",
trControl = modelControl)
set.seed(6517)
m_glm <- train(y ~ ., data=train_woe,method="glm",family=binomial(link='logit'),
trControl=modelControl)
final_under <- data.table(actual = test_woe$y,
predict(m_glm, newdata = test_woe, type = "prob"))
final_under <- final_under[,predict := ifelse(final_under$bad > 0.5,
"bad", "good")][,predict :=
factor(predict,levels = c("bad","good"))]
cm_under <- confusionMatrix(final_under$predict, test_woe$y)
View(cm_under)
cm_under
modelControl <- trainControl(method = "repeatedcv",
number = 5,
repeats = 2,
verboseIter = FALSE,
sampling = "up")
set.seed(6517)
m_glm <- train(y ~ ., data=train_woe,method="glm",family=binomial(link='logit'),
trControl=modelControl)
summary(m_glm)
final_under <- data.table(actual = test_woe$y,
predict(m_glm, newdata = test_woe, type = "prob"))
final_under <- final_under[,predict := ifelse(final_under$bad > 0.5,
"bad", "good")][,predict :=
factor(predict,levels = c("bad","good"))]
cm_under <- confusionMatrix(final_under$predict, test_woe$y)
cm_under
final_under <- data.table(actual = test_woe$y,
predict(model_rf_under, newdata = test_woe, type = "prob"))
final_under <- final_under[,predict := ifelse(final_under$bad > 0.5,
"bad", "good")][,predict :=
factor(predict,levels = c("bad","good"))]
cm_under <- confusionMatrix(final_under$predict, test_woe$y)
cm_under
train_woe = woebin_ply(
loan_mTrain, bins_adj)
test_woe = woebin_ply(
loan_mTest, bins_adj)
log_model_logit <- glm(y ~.,
family = binomial(link = logit), data = train_woe)
log_model_probit <- glm(y ~.,
family = binomial(link = probit), data = train_woe)
log_model_cloglog <-  glm(y ~.,
family = binomial(link = cloglog), data = train_woe)
# Make predictions for all models using the test set
predictions_logit <- predict(log_model_logit, newdata = test_woe, type = "response")
predictions_probit <- predict(log_model_probit, newdata = test_woe, type = "response")
predictions_cloglog <- predict(log_model_cloglog, newdata = test_woe, type = "response")
# Use a cut-off of 14% to make binary predictions-vectors
cutoff <- 0.14
class_pred_logit <- ifelse(predictions_logit > cutoff, 1, 0)
class_pred_probit <- ifelse(predictions_probit > cutoff, 1, 0)
class_pred_cloglog <- ifelse(predictions_cloglog > cutoff, 1, 0)
# Make a confusion matrix for the three models
tab_class_logit <- table(test_woe$y,class_pred_logit)
tab_class_probit <- table(test_woe$y,class_pred_probit)
tab_class_cloglog <-  table(test_woe$y,class_pred_cloglog)
# Compute the classification accuracy for all three models
acc_logit <- sum(diag(tab_class_logit)) / nrow(test_woe)
acc_probit <- sum(diag(tab_class_probit)) / nrow(test_woe)
acc_cloglog <- sum(diag(tab_class_cloglog)) / nrow(test_woe)
acc_logit
acc_probit
acc_cloglog
library(data.table)
library(scorecard)
library(caret)
library(DescTools)
options(scipen = 8)
loan = fread("C:/Users/pauke/Downloads/loan.csv")
loan <- loan[,y :=
ifelse(loan_status %in% c("Charged Off", "Default",
"Does not meet the credit policy. Status:Charged Off",
"In Grace Period","Late (16-30 days)",
"Late (31-120 days)"),"bad","good")]
loan <- loan[,y := factor(y,levels = c("bad","good"))]
knitr::kable(Desc(loan$y)[[1]][["freq"]])
loan_selected <- loan[,c("loan_amnt","int_rate","dti",
"purpose","term","annual_inc","home_ownership","emp_length","revol_bal","y")]
loan_m <- var_filter(loan_selected,y = "y")
names(loan_m)
trainIndex <- createDataPartition(loan_m$y, p = .08,
list = FALSE,
times = 1)
loan_mp <- loan_m[trainIndex,]
Desc(loan_m$y)
break_adj = list(
loan_amnt=c(8500,14000,20500))
bins_adj = woebin(
loan_mp, y="y",
breaks_list=break_adj,
print_step=0)
woebin_plot(bins_adj$loan_amnt)
set.seed(6715)
trainIndex <- createDataPartition(loan_mp$y, p = .85,
list = FALSE,
times = 1)
loan_mTrain <- loan_mp[ trainIndex,]
loan_mTest  <- loan_mp[-trainIndex,]
knitr::kable(Desc(loan_mTrain$y)[[1]][["freq"]])
train_woe = woebin_ply(
loan_mTrain, bins_adj)
test_woe = woebin_ply(
loan_mTest, bins_adj)
pred_logit <- predict(mlog_logit, newdata = test_woe, type = "response")
mlog_logit <- glm(y ~.,family = binomial(link = logit), data = train_woe)
mlog_probit <- glm(y ~.,family = binomial(link = probit), data = train_woe)
mlog_cloglog <- glm(y ~.,family = binomial(link = cloglog), data = train_woe)
pred_logit <- predict(mlog_logit, newdata = test_woe, type = "response")
pred_probit <- predict(mlog_probit, newdata = test_woe, type = "response")
pred_cloglog <- predict(mlog_cloglog, newdata = test_woe, type = "response")
perf_eva(test_woe$y, pred_logit, title="test")
pred_logit
Desc(pred_cloglog)
perf_train = perf_eva(test_woe$y, pred_logit, title="test")
roc(test_woe[,y], pred_probit)
library(pROC)
roc(test_woe[,y], pred_probit)
plot(pred_cloglog)
auc <- roc(test_woe[,y], pred_cloglog)
roc(test_woe[,y], pred_cloglog)
roc_logit <- roc(test_woe[,y], pred_logit)
roc_probit <- roc(test_woe[,y], pred_probit)
roc_cloglog <- roc(test_woe[,y], pred_cloglog)
roc.test(roc_logit,roc_probit,roc_cloglog)
plot(roc_logit,roc_probit,roc_cloglog)
roc_logit
roc_probit
roc_cloglog
roc.test(roc_logit,roc_probit,roc_cloglog)
roc.test(roc_logit,roc_probit, reuse.auc=FALSE)
roc.test(roc_cloglog,roc_probit, reuse.auc=FALSE)
roc_logit
roc_probit
roc_cloglog
# Use a cut-off of 14% to make binary predictions-vectors
cutoff <- 0.14
class_pred_logit <- ifelse(pred_logit > cutoff, 1, 0)
class_pred_probit <- ifelse(pred_probit > cutoff, 1, 0)
class_pred_cloglog <- ifelse(pred_cloglog > cutoff, 1, 0)
# Make a confusion matrix for the three models
tab_class_logit <- table(test_woe$y,class_pred_logit)
tab_class_probit <- table(test_woe$y,class_pred_probit)
tab_class_cloglog <-  table(test_woe$y,class_pred_cloglog)
# Compute the classification accuracy for all three models
acc_logit <- sum(diag(tab_class_logit)) / nrow(test_woe)
acc_probit <- sum(diag(tab_class_probit)) / nrow(test_woe)
acc_cloglog <- sum(diag(tab_class_cloglog)) / nrow(test_woe)
acc_logit
acc_probit
acc_cloglog
rm(class_pred_logit,class_pred_probit,class_pred_cloglog,
tab_class_logit,tab_class_probit,tab_class_cloglog,acc_probit,acc_logit,
acc_cloglog)
card = scorecard(bins_adj, mlog_cloglog)
data.table::rbindlist(card, fill=TRUE)[c(1,37:40),1:4]
card[["annual_inc"]]
train_score = scorecard_ply(loan_mTrain, card, only_total_score=TRUE, print_step=0)
test_score = scorecard_ply(loan_mTest, card, only_total_score=TRUE, print_step=0)
View(train_score)
View(test_score)
perf_eva(loan_mTest$y, pred_cloglog, title="test")
pred_cloglog
perf_eva
perf_eva(test_woe$y, pred_cloglog, title="test")
test_woe$y
scorecard::perf_eva(test_woe$y, pred_cloglog, title="test")
pred_cloglog <- predict.train(mlog_cloglog, newdata = test_woe, type = "response")
pred_cloglog <- predict(mlog_cloglog, newdata = test_woe, type = "response")
train_score = scorecard_ply(loan_mTrain, card, only_total_score=F, print_step=0)
test_score = scorecard_ply(loan_mTest, card, only_total_score=F, print_step=0)
View(train_score)
perf_psi(
score = list(train = train_score, test = test_score),
label = list(train = loan_mTrain$y, test = loan_mTtest$y) )
perf_psi(
score = list(train = train_score, test = test_score),
label = list(train = loan_mTrain$y, test = loan_mTest$y) )
psi <- perf_psi(
score = list(train = train_score, test = test_score),
label = list(train = loan_mTrain$y, test = loan_mTest$y) )
psi$psi
knitr::kable(psi$psi)
View(psi)
psi$pic$score
blogdown:::serve_site()
run servr::daemon_stop("1932750307416")
servr::daemon_stop("1932750307416")
