---
title: "Workflow with Caret"
author: "pauke"
date: "1/26/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)


```

```{r message=FALSE, warning=FALSE}
library(knitr)
library(caret)
library(DiagrammeR)#for the flowchart
library(DescTools)# for summary of data
library(proxy)#maxDissim
library(mlbench)#data zoo
library(data.table)
library(fastDummies) #for dummy variables

options(scipen=8)

```


## Foreword

This is a workflow about [caret](https://topepo.github.io/caret/), which is a creating predicted models collecting toolkit framework, integrating all activities related to model development from other R packages. Caret can be also treated as a tool to get started or get familiar with machine learning, especially in supervised and unsupervised learning part that is good at. 

The article is about the usual thought of using caret and machine learning, more focusing on general use situation. And I'll try to offer a holistic view for machine learning beginners and the way to find more concrete field. That means I would not present the specific algorithms, tuning methods or fitted fields.

## Structure

All tools in caret can be classified in the [ducument](https://topepo.github.io/caret/) like this:

> - data splitting
> - pre-processing(depending on data set situation)
> - feature selection
> - model tuning using resampling
> - variable importance estimation

Link to the crucial function in each part, all the part of caret workflow is:


```{r echo=FALSE, message=FALSE, warning=FALSE}

DiagrammeR::mermaid('
graph LR
D_E[Data Exploration/Visualization]
P[Preprocessing]
D_S[Data Splitting]
M[Modeling]
M_E[Model Evaluation]

D_Es("featureplot()<br>dotPlot()<br>lift()<br>plotClassProbs()")
Ps("preProcess()<br>nearZeroVar()<br>findCorrelation()<br>findLinearCombos()")
D_Ss("createDataPartition()<br>createTimeSlices()")
Ms("train()<br>trainControl()")
M_Es("confusionMatrix()<br>resample()<br>postResample()")
Finishs(fit the final model with<br> optimal parameter set)

D_E --> D_S 
D_S --> P  
P --> M
M --tuning or parameters <br> set changing--> M_E
M_E -- "if largest performance value <br>or smallest mean squared error"--> Finish

D_E --- D_Es
P --- Ps
D_S --- D_Ss
M --- Ms
M_E --- M_Es
Finish --- Finishs

classDef default fill:#ffffe6,stroke:#333,stroke-width:2px

style D_E stroke-width:4px
style P stroke-width:4px,stroke-dasharray: 5, 5
style D_S stroke-width:4px
style M stroke-width:4px
style M_E stroke-width:4px
style Finish stroke-width:4px

', height =500, width =950
)

```


By the way,as I said in foreword, this post would like more pay attention on the process of caret using. The part of data exploration is deeply dependent on the familiarity about the data you get to deal with, and can be replaced by another professional packages. If you are more interesting on the visualization tools of caret, just jump to this [chapter](http://topepo.github.io/caret/visualizations.html).

## Data Splitting

More specific matter of data splitting, you can find on the [document](http://topepo.github.io/caret/data-splitting.html) and the this article [Preprocessign Data with caret](http://rismyhammer.com/ml/Pre-Processing.html)

situation | splitting mathods
----------|------------------
supervised learning|`createDataPartition()`
unsupervised learning | `maxDissim()`
time serias | `trainControl(method = "timeslice"...)`


### Based on Outcome

`createDataPartition()` is the splitting function that data set has clear dependent variables, which means it's fitted for supervised learning. `createDataPartition()`is the one of the most useful feature function of caret package, which makes data splitting to be more orderly and approachable.

This method can generate balant data split. When the dependent variables are factor variables, the splitting will based on the distribution of factors.

```{r echo=TRUE, warning=FALSE}

data(scat)
#set seed and create splitting index
set.seed(3456)
trainIndex <- createDataPartition(scat$Species, p = .8, 
                                  list = FALSE, 
                                  times = 1)
#the distribution of dependent variables
knitr::kable(Desc(scat$Species)[[1]][["freq"]]) 
```

```{r}
#splitting

scatTrain <- scat[ trainIndex,]
scatTest  <- scat[-trainIndex,]

knitr::kable(Desc(scatTrain$Species)[[1]][["freq"]])

```

### Based on Predictors
If we manage to get a unsupervised learning prediction, the maxDissim function is a splitting good way using a maximum dissimilarity approach. About the method:

>Suppose there is a data set A with m samples and a larger data set B with n samples. We may want to create a subâ€“sample from B that is diverse when compared to A. To do this, for each sample in B, the function calculates the m dissimilarities between each point in A. The most dissimilar point in B is added to A and the process continues.

In a short, sampling out A as the start set, and getting the final set against start set by largest distance.

```{r echo=TRUE, warning=FALSE}

data(cars)

testing <- scale(cars[, c("Price", "Mileage")])
set.seed(5)
## A random sample of 5 data points
startSet <- sample(1:dim(testing)[1], 5)
samplePool <- testing[-startSet,]
start <- testing[startSet,]
newSamp <- maxDissim(start, samplePool, n = 20)
```

result of the splitting:

```{r}
plot(testing[-newSamp,], 
          col = "darkgrey")
points(start, pch = 16, cex = .7)
     
     for(i in seq(along = newSamp))
          points(
               samplePool[newSamp[i],1], 
               samplePool[newSamp[i],2], 
               pch = paste(i), col = "darkred")
```

More maxDissim methods, please check this [article](http://rismyhammer.com/ml/Pre-Processing.html)'s Splitting Based on Predictors part.


### Time Serias Data Splitting

`createTimeSlices()` is the sister function of `createDataPartition()` to handle time serias data. Three argument of the function is:

- `initialWindow`: the initial number of consecutive values in each training set sample
- `horizon`: The number of consecutive values in test set sample
- `fixedWindow`: A logical: if FALSE, the training set always start at the first sample and the training set size will vary over data splits.

The example of the function usage is also in this [articles](http://rismyhammer.com/ml/Pre-Processing.html)'s Time Series Data Splitting part.

```{r}
data(economics)
# which is often used in the `trainControl()` set
myTimeControl <- trainControl(method = "timeslice", initialWindow = 36, horizon = 12, fixedWindow = TRUE)

plsFitTime <- train(unemploy ~ pce + pop + psavert, data = economics, method = "pls",
                    preProc = c("center", "scale"), trControl = myTimeControl)

```


## Preprocessing

This part is based on the conclution of your data exploration. You need to consider what situation of your data that you need to deal with before starting build your model. According to the situation of the function facing to, preprocessing function of caret can be sorted as:


situation category|function
----------|--------
categorical/dichotomous variables| `dummyVars()`,`data.table()`
unbalance| `nearZeroVar()`,`preProcess(df,method = c("center", "scale"))`
missing value | `preProcess(df,method = c("center", "scale")/"knnImpute")`
too much predictors| `preProcess(df, method = "BoxCox"/"pca")`
class distance | `classDist()`

As you can see, there are a lot of situations that might causes model prediction fail, and there are more solution to fix the situations you face. No matter how unique you are getting the data set problems, **stable, numerical, centralized and no missing** data set may lead a better result of model. 

### `preProcess()` Function Set

Package caret provised a useful function,`preProcess()`,to handle the preprocessing's situations. 

Function preProcess contain two parts: `preProcess()`procession and `predict.preProcess()`procession. `preProcess()`estimates the required parameters for each operation and `predict.preProcess()` is used to apply them to specific data sets. This function can also be interfaces when calling the train function.

`preProcValues <- preProcess(dataToHandle, method = c(),...other Arguments)`
`dataTransformed <- predict(preProcValues, dataToHandle)`

Specific example:

```{r}
data(oil)

inTrain <- sample(seq(along = fattyAcids), length(fattyAcids)*0.7)

training <- fattyAcids[inTrain,]
str(training)

preProcValues <- preProcess(training, method = c("center", "scale"))

trainTransformed <- predict(preProcValues, training)
str(trainTransformed)

```


The list of function preProcess methods:

- **range**: Normalize values so it ranges between 0 and 1
- **center**: Subtract Mean
- **scale**: Divide by standard deviation
- **BoxCox**: Remove skewness leading to normality. Values must be > 0
- **YeoJohnson**: Like BoxCox, but works for negative values.
- **expoTrans**: Exponential transformation, works for negative values.
- **pca**: Replace with principal components
- **ica**: Replace with independent components
- **spatialSign**: Project the data to a unit circle

More information about how function preProcess is used, you can find in `??preProcess` and this [article](http://rismyhammer.com/ml/Pre-Processing.html#split-data)


### Other preprocessing function

#### Turning Numerical 

There are two methods to deal with the categorical or dichotomous variables:


##### Recode the Categorical Variable as Numeric

```{r}

data("Zoo")
Zoo$animalNames <- rownames(Zoo)

#categorical variable
unique(Zoo$type)
## recode the categorical variable as numeric
value= unique(Zoo$type)
zoo <- setDT(Zoo)[,type:=as.character(type)][.(type = value,to = 1:length(value)),on = "type",type :=i.to]
unique(zoo$type)

```

##### `dummyVars()` in Caret

```{r}
#dichotomous variable
## dummyVars() in caret
head(model.matrix(type ~ ., data = zoo[,c(1:4,17)]),4)

dummies <- dummyVars(type ~ ., data = zoo[,c(1:4,17)])
head(predict(dummies, newdata = zoo),4)
```

##### `dummy_cols()` in FastDummies

About the function usage, you find more info in the [article](https://cran.r-project.org/web/packages/fastDummies/vignettes/making-dummy-variables.html).

```{r}
## dummyVars() in caret
data("Zoo")
Zoo$animalNames <- rownames(Zoo)

zooDummy <- dummy_cols(Zoo[,c(1:4,17)])
head(zooDummy,4)
```

#### Removing Correlated 

`findCorrelation()` is the tool to find the independences in model, that are be correlated with each other. Based on the result, you can remove or reduce the level of correlation between the independences.

check the correlated situation of the independences:

```{r}
data(Zoo)
descrCor <- cor(Zoo[,-17])
summary(descrCor[upper.tri(descrCor)])
```

set a cutoff line and find the independences above:

```{r}
CUTOFF <- 0.85 
cor_matrix <- cor(Zoo[,-17]) 
cor_high <- findCorrelation(cor_matrix, CUTOFF)
high_cor_remove <- row.names(cor_matrix)[cor_high] 
high_cor_remove
#removingCorZoo <- Zoo[,-high_cor_remove]
```

## Basic Model Training

The `train()` is the center of the whole model training(About the origin of the function, [there](http://www.jstatsoft.org/article/view/v028i05/v28i05.pdf) is an illastration). 

Quick example show of the function `train()`


The `train()` function consists of these arguments:

x: a matrix or data frame of predictors. Currently, the function only accepts numeric values (i.e., no factors or character variables). In some cases, the model.matrix function may be needed to generate a data frame or matrix of purely numeric data
y: a numeric or factor vector of outcomes. The function determines the type of problem (classification or regression) from the type of the response given in this argument.
method: a character string specifying the type of model to be used. See Table 1 for the possible values.

metric: a character string with values of "Accuracy", "Kappa", "RMSE" or "Rsquared". This value determines the objective function used to select the final model. For example, selecting "Kappa" makes the function select the tuning parameters with the largest value of the mean Kappa statistic computed from the held-out samples.
trControl: takes a list of control parameters for the function. The type of resampling as well as the number of resampling iterations can be set using this list. The function trainControl can be used to compute default parameters. The default number of resampling iterations is 25, which may be too small to obtain accurate performance estimates in some cases.
tuneLength: controls the size of the default grid of tuning parameters. For each model, train will select a grid of complexity parameters as candidate values. For the SVM model, the function will tune over C = 10âˆ’1,1,10. To expand the size of the default list, the tuneLength argument can be used. By selecting tuneLength = 5, values of C ranging from 0.1 to 1, 000 are evaluated.
tuneGrid: can be used to define a specific grid of tuning parameters. See the example below.
... : the three dots can be used to pass additional arguments to the functions listed in Table 1. For example, we have already centered and scaled the predictors, so the argument scaled = FALSE can be passed to the ksvm function to avoid duplication of the pre-processing.



